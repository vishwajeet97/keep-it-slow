class SlowDownExperienceReplayAgent(ExperienceReplayAgent):
    def __init__(self,
                 env: gym.Env,
                 epochs=10100,
                 epsilon=0.1,
                 N=600,
                 M=64,
                 num_train_iters=50,
                 num_ep_update_value=1601,
                 decision_interval=3,
                 gamma=1.,
                 layer_size=[64],
                 lr=1e-1):

Updating Q
Avg timesteps per episode: 16.726667
Num eps: 600
Experience length: 3169
Updating Q
Avg timesteps per episode: 9.668333
Num eps: 1200
Experience length: 4935
Updating Q
Avg timesteps per episode: 9.681667
Num eps: 1800
Experience length: 6715
Updating Q
Avg timesteps per episode: 66.583333
Num eps: 2400
Experience length: 19851
Updating Q
Avg timesteps per episode: 94.258333
Num eps: 3000
Experience length: 38498
Updating Q
Avg timesteps per episode: 78.041667
Num eps: 3600
Experience length: 53905
Updating Q
Avg timesteps per episode: 119.330000
Num eps: 4200
Experience length: 77616
Updating Q
Avg timesteps per episode: 128.491667
Num eps: 4800
Experience length: 103100
Updating Q
Avg timesteps per episode: 132.065000
Num eps: 5400
Experience length: 129283
Updating Q
Avg timesteps per episode: 68.851667
Num eps: 6000
Experience length: 142788
Updating Q
Avg timesteps per episode: 89.178333
Num eps: 6600
Experience length: 160432
Updating Q
Avg timesteps per episode: 120.221667
Num eps: 7200
Experience length: 184255
Updating Q
Avg timesteps per episode: 78.700000
Num eps: 7800
Experience length: 199788
Updating Q
Avg timesteps per episode: 134.558333
Num eps: 8400
Experience length: 226452
Updating Q
Avg timesteps per episode: 124.223333
Num eps: 9000
Experience length: 251097
Updating Q
Avg timesteps per episode: 113.273333
Num eps: 9600
Experience length: 273564